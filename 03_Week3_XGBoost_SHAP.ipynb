{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 03 - Week 3: XGBoost + SHAP\n\nSteps:\n1. Load processed data.\n2. Train/test split with stratification.\n3. Optional hyperparameter search.\n4. Train XGBoost with class imbalance handling.\n5. Evaluate and compare against baseline.\n6. Interpret using SHAP."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "import json\nimport joblib\nimport numpy as np\nimport pandas as pd\nimport shap\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    roc_auc_score, average_precision_score, confusion_matrix, roc_curve,\n    precision_recall_curve\n)\nfrom xgboost import XGBClassifier\n\nRANDOM_STATE = 42\nDATA_PATH = Path('data/processed/hits_dataset.csv')\nMODEL_PATH = Path('models/final_xgboost.pkl')\nSKIP_TUNING = True\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "df = pd.read_csv(DATA_PATH)\nfeature_cols = [c for c in df.columns if c not in ['is_hit', 'name', 'artist', 'id', 'release_date']]\nX = df[feature_cols]\ny = df['is_hit']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n)\n\npos = y_train.sum()\nneg = len(y_train) - pos\nscale_pos_weight = neg / pos if pos else 1.0\nprint(f\"scale_pos_weight: {scale_pos_weight:.2f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Hyperparameter search (optional)\nSet `SKIP_TUNING=False` for a broader search; defaults run quickly."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "base_model = XGBClassifier(\n    objective='binary:logistic',\n    eval_metric='aucpr',\n    n_estimators=300,\n    learning_rate=0.05,\n    max_depth=6,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    reg_lambda=1.0,\n    scale_pos_weight=scale_pos_weight,\n    random_state=RANDOM_STATE,\n    n_jobs=-1\n)\n\nif not SKIP_TUNING:\n    param_dist = {\n        'max_depth': [4, 6, 8],\n        'min_child_weight': [1, 5, 10],\n        'subsample': [0.7, 0.9, 1.0],\n        'colsample_bytree': [0.7, 0.9, 1.0],\n        'learning_rate': [0.01, 0.05, 0.1],\n        'n_estimators': [200, 400, 600]\n    }\n    search = RandomizedSearchCV(\n        estimator=base_model,\n        param_distributions=param_dist,\n        n_iter=15,\n        scoring='average_precision',\n        cv=3,\n        random_state=RANDOM_STATE,\n        verbose=1,\n        n_jobs=-1\n    )\n    search.fit(X_train, y_train)\n    model = search.best_estimator_\n    print(f\"Best params: {search.best_params_}\")\nelse:\n    model = base_model\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Train with early stopping"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "model.fit(\n    X_train, y_train,\n    eval_set=[(X_test, y_test)],\n    eval_metric='aucpr',\n    verbose=False,\n)\n\ny_pred = model.predict(X_test)\ny_proba = model.predict_proba(X_test)[:, 1]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Evaluation"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "metrics_xgb = {\n    'accuracy': accuracy_score(y_test, y_pred),\n    'precision': precision_score(y_test, y_pred, zero_division=0),\n    'recall': recall_score(y_test, y_pred, zero_division=0),\n    'f1': f1_score(y_test, y_pred, zero_division=0),\n    'roc_auc': roc_auc_score(y_test, y_proba),\n    'pr_auc': average_precision_score(y_test, y_proba)\n}\nprint(json.dumps(metrics_xgb, indent=2))\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "cm = confusion_matrix(y_test, y_pred)\nfig, ax = plt.subplots(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Greens', ax=ax)\nax.set_xlabel('Predicted')\nax.set_ylabel('Actual')\nax.set_title('XGBoost Confusion Matrix')\nplt.tight_layout()\nplt.savefig('figures/xgboost_confusion_matrix.png', dpi=300)\nplt.close()\n\nfpr, tpr, _ = roc_curve(y_test, y_proba)\nprecision, recall, _ = precision_recall_curve(y_test, y_proba)\n\nplt.figure(figsize=(6,5))\nplt.plot(fpr, tpr, label=f\"ROC-AUC: {metrics_xgb['roc_auc']:.3f}\")\nplt.plot([0,1],[0,1],'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('XGBoost ROC Curve')\nplt.legend()\nplt.tight_layout()\nplt.savefig('figures/xgboost_roc_curve.png', dpi=300)\nplt.close()\n\nplt.figure(figsize=(6,5))\nplt.plot(recall, precision, label=f\"PR-AUC: {metrics_xgb['pr_auc']:.3f}\")\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('XGBoost Precision-Recall Curve')\nplt.legend()\nplt.tight_layout()\nplt.savefig('figures/xgboost_pr_curve.png', dpi=300)\nplt.close()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. SHAP interpretability"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "explainer = shap.TreeExplainer(model)\nsample_size = min(1000, len(X_train))\nshap_background = X_train.sample(sample_size, random_state=RANDOM_STATE)\nshap_values = explainer.shap_values(shap_background)\n\nshap.summary_plot(shap_values, shap_background, show=False)\nplt.tight_layout()\nplt.savefig('figures/shap_summary_detailed.png', dpi=300)\nplt.close()\n\nshap.plots.bar(shap_values, max_display=15, show=False)\nplt.tight_layout()\nplt.savefig('figures/shap_feature_importance.png', dpi=300)\nplt.close()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Persist model"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\njoblib.dump(model, MODEL_PATH)\nprint(f\"Saved XGBoost model to {MODEL_PATH}\")\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}