{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# 01 - Week 1: Data Setup & EDA\n\nTasks:\n1. Load raw Spotify datasets (tracks + Top 100 list).\n2. Merge and label tracks as HIT/NON-HIT.\n3. Explore class imbalance and feature distributions.\n4. Save the processed dataset for modeling."
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1. Imports and settings"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "import os\nimport json\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom fuzzywuzzy import fuzz\nfrom fuzzywuzzy import process\n\nwarnings.filterwarnings('ignore')\nplt.style.use('seaborn-v0_8')\nRANDOM_STATE = 42\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 2. Configuration\nUpdate paths here if your files live elsewhere."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "RAW_TRACKS_PATH = Path('data/raw/tracks.csv')\nTOP100_PATH = Path('data/raw/top100_tracks.csv')\nPROCESSED_PATH = Path('data/processed/hits_dataset.csv')\n\nAUDIO_FEATURES = [\n    'danceability', 'energy', 'loudness', 'speechiness',\n    'acousticness', 'instrumentalness', 'liveness', 'valence',\n    'tempo'\n]\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 3. Load datasets\nAdjust column names if your source files differ."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "tracks_df = pd.read_csv(RAW_TRACKS_PATH)\ntop100_df = pd.read_csv(TOP100_PATH)\n\nprint(tracks_df.head())\nprint(top100_df.head())\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4. Label hits\nPriority order: (1) Spotify track ID match, (2) name + artist exact match, (3) fuzzy match fallback."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "def label_hits(tracks: pd.DataFrame, hits: pd.DataFrame) -> pd.DataFrame:\n    tracks = tracks.copy()\n    hits = hits.copy()\n\n    # Standardize column names\n    rename_map = {\n        'track_name': 'name',\n        'track': 'name',\n        'artists': 'artist',\n        'artists_name': 'artist',\n    }\n    tracks.rename(columns=rename_map, inplace=True)\n    hits.rename(columns=rename_map, inplace=True)\n\n    tracks['name'] = tracks['name'].str.lower().str.strip()\n    tracks['artist'] = tracks['artist'].str.lower().str.strip()\n    hits['name'] = hits['name'].str.lower().str.strip()\n    hits['artist'] = hits['artist'].str.lower().str.strip()\n\n    # Strategy 1: Spotify ID\n    if 'id' in tracks.columns and 'id' in hits.columns:\n        hit_ids = set(hits['id'].dropna())\n        tracks['is_hit'] = tracks['id'].isin(hit_ids)\n    else:\n        tracks['is_hit'] = False\n\n    # Strategy 2: exact name + artist match for remaining rows\n    remaining = tracks[~tracks['is_hit']]\n    hit_pairs = set(zip(hits['name'], hits['artist']))\n    exact_mask = remaining.apply(lambda r: (r['name'], r['artist']) in hit_pairs, axis=1)\n    tracks.loc[remaining.index, 'is_hit'] = exact_mask.values | tracks.loc[remaining.index, 'is_hit']\n\n    # Strategy 3: fuzzy match\n    remaining = tracks[~tracks['is_hit']]\n    def fuzzy_match(row):\n        candidate = f\"{row['name']} - {row['artist']}\"\n        choices = [f\"{n} - {a}\" for n, a in zip(hits['name'], hits['artist'])]\n        if not choices:\n            return False\n        match, score = process.extractOne(candidate, choices, scorer=fuzz.token_sort_ratio)\n        return score >= 90\n\n    tracks.loc[remaining.index, 'is_hit'] = remaining.apply(fuzzy_match, axis=1)\n    return tracks\n\ntracks_labeled = label_hits(tracks_df, top100_df)\nprint(tracks_labeled['is_hit'].value_counts(normalize=True))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5. Feature selection and cleaning"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "# Keep audio features plus identifiers for reference\navailable_features = [c for c in AUDIO_FEATURES if c in tracks_labeled.columns]\nselected_cols = ['name', 'artist', 'id', 'release_date', 'is_hit'] + available_features\nprocessed = tracks_labeled[selected_cols].dropna(subset=available_features)\n\n# Ensure correct dtypes\nprocessed['release_date'] = pd.to_datetime(processed['release_date'], errors='coerce')\nprocessed = processed.dropna(subset=['release_date'])\n\n# Temporal features\nprocessed['release_year'] = processed['release_date'].dt.year\nprocessed['release_month'] = processed['release_date'].dt.month\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 6. Class balance analysis"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "hit_rate = processed['is_hit'].mean()\nprint(f\"Hit rate: {hit_rate:.3%} ({processed['is_hit'].sum()} hits / {len(processed)} tracks)\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 7. Visualizations"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "fig, axes = plt.subplots(len(available_features), 1, figsize=(8, 4*len(available_features)), constrained_layout=True)\nif len(available_features) == 1:\n    axes = [axes]\nfor ax, feat in zip(axes, available_features):\n    sns.boxplot(data=processed, x='is_hit', y=feat, ax=ax)\n    ax.set_title(f\"{feat} by hit status\")\nplt.savefig('figures/feature_distributions.png', dpi=300)\nplt.close()\n\nplt.figure(figsize=(10,6))\nsns.countplot(data=processed, x='release_year', hue='is_hit')\nplt.title('Tracks by year and hit status')\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.savefig('figures/tracks_by_year.png', dpi=300)\nplt.close()\n\ncorr = processed[available_features].corr()\nplt.figure(figsize=(10,8))\nsns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')\nplt.title('Feature correlation')\nplt.tight_layout()\nplt.savefig('figures/correlation_matrix.png', dpi=300)\nplt.close()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 8. Save processed data"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "outputs": [],
      "execution_count": null,
      "source": "PROCESSED_PATH.parent.mkdir(parents=True, exist_ok=True)\nprocessed.to_csv(PROCESSED_PATH, index=False)\nprint(f\"Saved processed dataset to {PROCESSED_PATH.resolve()}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Proceed to `02_Week2_Baseline_Modeling.ipynb`."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}