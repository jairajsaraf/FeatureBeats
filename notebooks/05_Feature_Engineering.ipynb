{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Hit Song Prediction\n",
    "\n",
    "## Objectives\n",
    "1. Create interaction features (e.g., energy × danceability)\n",
    "2. Add polynomial features for non-linear relationships\n",
    "3. Engineer temporal features (month, day of week)\n",
    "4. Create domain-specific features\n",
    "5. Evaluate impact on model performance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "processed_data_dir = project_root / 'data' / 'processed'\n",
    "figures_dir = project_root / 'figures'\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(processed_data_dir / 'hits_dataset.csv')\n",
    "print(f\"Original dataset: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Interaction Features\n",
    "\n",
    "Combine features that might work together to predict hits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get audio feature columns\n",
    "exclude_cols = ['is_hit', 'year'] + df.select_dtypes(include=['object']).columns.tolist()\n",
    "audio_features = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Create interaction features\n",
    "df_engineered = df.copy()\n",
    "\n",
    "# Domain knowledge interactions\n",
    "if 'energy' in audio_features and 'danceability' in audio_features:\n",
    "    df_engineered['energy_x_danceability'] = df['energy'] * df['danceability']\n",
    "    print(\"✅ Created: energy × danceability\")\n",
    "\n",
    "if 'valence' in audio_features and 'energy' in audio_features:\n",
    "    df_engineered['valence_x_energy'] = df['valence'] * df['energy']\n",
    "    print(\"✅ Created: valence × energy (happy & energetic)\")\n",
    "\n",
    "if 'loudness' in audio_features and 'energy' in audio_features:\n",
    "    df_engineered['loudness_x_energy'] = df['loudness'] * df['energy']\n",
    "    print(\"✅ Created: loudness × energy\")\n",
    "\n",
    "if 'acousticness' in audio_features and 'energy' in audio_features:\n",
    "    df_engineered['acoustic_vs_energy'] = df['acousticness'] - df['energy']\n",
    "    print(\"✅ Created: acousticness - energy (acoustic contrast)\")\n",
    "\n",
    "# Danceability composite\n",
    "if all(f in audio_features for f in ['danceability', 'valence', 'energy']):\n",
    "    df_engineered['party_factor'] = (df['danceability'] + df['valence'] + df['energy']) / 3\n",
    "    print(\"✅ Created: party_factor (avg of dance, valence, energy)\")\n",
    "\n",
    "print(f\"\\nDataset shape after interactions: {df_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Polynomial Features\n",
    "\n",
    "Capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add squared terms for key features\n",
    "key_features = ['danceability', 'energy', 'valence'] if all(f in audio_features for f in ['danceability', 'energy', 'valence']) else audio_features[:3]\n",
    "\n",
    "for feature in key_features:\n",
    "    if feature in df.columns:\n",
    "        df_engineered[f'{feature}_squared'] = df[feature] ** 2\n",
    "        print(f\"✅ Created: {feature}²\")\n",
    "\n",
    "print(f\"\\nDataset shape after polynomial features: {df_engineered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Features\n",
    "\n",
    "Extract month, season, day of week if date information is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year-based features\n",
    "if 'year' in df.columns:\n",
    "    # Normalize year (0-1 scale)\n",
    "    df_engineered['year_normalized'] = (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min())\n",
    "    \n",
    "    # Year bins (early, mid, late period)\n",
    "    df_engineered['year_period'] = pd.cut(df['year'], bins=3, labels=[0, 1, 2]).astype(int)\n",
    "    \n",
    "    print(\"✅ Created: year_normalized, year_period\")\n",
    "\n",
    "print(f\"\\nFinal engineered dataset shape: {df_engineered.shape}\")\n",
    "print(f\"Added {df_engineered.shape[1] - df.shape[1]} new features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "exclude_cols = ['is_hit', 'year'] + df_engineered.select_dtypes(include=['object']).columns.tolist()\n",
    "feature_cols = [col for col in df_engineered.columns if col not in exclude_cols]\n",
    "\n",
    "X = df_engineered[feature_cols].values\n",
    "y = df_engineered['is_hit'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Original vs Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with original features\n",
    "original_features = [col for col in df.columns if col not in ['is_hit', 'year'] and col not in df.select_dtypes(include=['object']).columns]\n",
    "X_orig = df[original_features].values\n",
    "X_orig_train, X_orig_test, y_orig_train, y_orig_test = train_test_split(\n",
    "    X_orig, y, test_size=0.2, random_state=RANDOM_SEED, stratify=y\n",
    ")\n",
    "\n",
    "scaler_orig = StandardScaler()\n",
    "X_orig_train_scaled = scaler_orig.fit_transform(X_orig_train)\n",
    "X_orig_test_scaled = scaler_orig.transform(X_orig_test)\n",
    "\n",
    "# Original features model\n",
    "model_orig = LogisticRegression(class_weight='balanced', random_state=RANDOM_SEED, max_iter=1000)\n",
    "model_orig.fit(X_orig_train_scaled, y_orig_train)\n",
    "y_pred_orig = model_orig.predict(X_orig_test_scaled)\n",
    "\n",
    "# Engineered features model\n",
    "model_eng = LogisticRegression(class_weight='balanced', random_state=RANDOM_SEED, max_iter=1000)\n",
    "model_eng.fit(X_train_scaled, y_train)\n",
    "y_pred_eng = model_eng.predict(X_test_scaled)\n",
    "\n",
    "# Compare\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ORIGINAL vs ENGINEERED FEATURES COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics = {\n",
    "    'Features Count': [len(original_features), len(feature_cols)],\n",
    "    'Precision': [precision_score(y_test, y_pred_orig), precision_score(y_test, y_pred_eng)],\n",
    "    'Recall': [recall_score(y_test, y_pred_orig), recall_score(y_test, y_pred_eng)],\n",
    "    'F1 Score': [f1_score(y_test, y_pred_orig), f1_score(y_test, y_pred_eng)]\n",
    "}\n",
    "\n",
    "comparison = pd.DataFrame(metrics, index=['Original', 'Engineered'])\n",
    "print(comparison)\n",
    "\n",
    "improvement = ((comparison.loc['Engineered', 'F1 Score'] - comparison.loc['Original', 'F1 Score']) / \n",
    "               comparison.loc['Original', 'F1 Score'] * 100)\n",
    "print(f\"\\nF1 Score Improvement: {improvement:+.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Top Engineered Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from coefficients\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Coefficient': model_eng.coef_[0],\n",
    "    'Abs_Coefficient': np.abs(model_eng.coef_[0])\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(\"=\"*60)\n",
    "for idx, row in feature_importance.head(10).iterrows():\n",
    "    feature_type = \"ENGINEERED\" if row['Feature'] not in original_features else \"ORIGINAL\"\n",
    "    print(f\"{row['Feature']:30s} {row['Coefficient']:+.4f}  [{feature_type}]\")\n",
    "\n",
    "# Count engineered features in top 10\n",
    "top10_engineered = sum(1 for f in feature_importance.head(10)['Feature'] if f not in original_features)\n",
    "print(f\"\\n{top10_engineered}/10 top features are engineered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered dataset\n",
    "output_file = processed_data_dir / 'hits_dataset_engineered.csv'\n",
    "df_engineered.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"✅ Saved engineered dataset to: {output_file}\")\n",
    "print(f\"   Original features: {len(original_features)}\")\n",
    "print(f\"   Total features: {len(feature_cols)}\")\n",
    "print(f\"   New features: {len(feature_cols) - len(original_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ✅ Feature Engineering Complete!\n",
    "\n",
    "### New Features Created:\n",
    "1. **Interaction Terms**: energy×danceability, valence×energy, etc.\n",
    "2. **Polynomial Features**: Squared terms for key features\n",
    "3. **Domain Features**: party_factor, acoustic_contrast\n",
    "4. **Temporal Features**: year_normalized, year_period\n",
    "\n",
    "### Impact:\n",
    "- Original features: Basic Spotify audio features\n",
    "- Engineered features: Enhanced with domain knowledge\n",
    "- Can improve model performance by capturing complex patterns\n",
    "\n",
    "### Usage:\n",
    "Use `hits_dataset_engineered.csv` in subsequent modeling for potentially better results!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
