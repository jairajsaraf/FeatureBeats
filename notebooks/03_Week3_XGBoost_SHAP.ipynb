{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 3 \u2013 XGBoost and SHAP Analysis\n",
        "\n",
        "Train an XGBoost classifier with imbalance-aware parameters, optionally tune hyperparameters, and generate SHAP explanations to understand feature contributions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import shap\n",
        "from sklearn.metrics import (ConfusionMatrixDisplay, average_precision_score,\n",
        "                             classification_report, confusion_matrix, precision_recall_curve,\n",
        "                             roc_auc_score, roc_curve)\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "DATA_PATH = Path('data/processed/hits_dataset.csv')\n",
        "BASELINE_METRICS = Path('models/baseline_metrics.json')\n",
        "FIG_DIR = Path('figures')\n",
        "MODEL_DIR = Path('models')\n",
        "FIG_DIR.mkdir(exist_ok=True)\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "assert DATA_PATH.exists(), 'Run Week 1 notebook first to generate hits_dataset.csv'\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "feature_candidates = [\n",
        "    'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
        "    'instrumentalness', 'liveness', 'valence', 'tempo'\n",
        "]\n",
        "features = [f for f in feature_candidates if f in df.columns]\n",
        "target = 'is_hit'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "pos = (y_train == 1).sum()\n",
        "neg = (y_train == 0).sum()\n",
        "scale_pos_weight = neg / pos\n",
        "print(f'scale_pos_weight: {scale_pos_weight:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train XGBoost (toggle tuning with `SKIP_TUNING`)\n",
        "\n",
        "Use a modest randomized search for better performance, or set `SKIP_TUNING=True` for a faster run. Imbalance is handled via `scale_pos_weight` and evaluation focuses on PR-AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "SKIP_TUNING = True\n",
        "\n",
        "base_params = dict(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1.0,\n",
        "    objective='binary:logistic',\n",
        "    eval_metric='aucpr',\n",
        "    scale_pos_weight=scale_pos_weight,\n",
        "    random_state=42,\n",
        "    n_jobs=4,\n",
        ")\n",
        "\n",
        "if SKIP_TUNING:\n",
        "    best_params = base_params\n",
        "else:\n",
        "    search_space = {\n",
        "        'model__n_estimators': [200, 300, 500],\n",
        "        'model__learning_rate': [0.05, 0.1, 0.2],\n",
        "        'model__max_depth': [4, 6, 8],\n",
        "        'model__subsample': [0.7, 0.8, 0.9],\n",
        "        'model__colsample_bytree': [0.7, 0.8, 0.9],\n",
        "        'model__min_child_weight': [1, 3, 5],\n",
        "        'model__gamma': [0, 0.25, 0.5]\n",
        "    }\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', XGBClassifier(**base_params))\n",
        "    ])\n",
        "    search = RandomizedSearchCV(\n",
        "        pipeline,\n",
        "        param_distributions=search_space,\n",
        "        n_iter=15,\n",
        "        scoring='average_precision',\n",
        "        n_jobs=4,\n",
        "        cv=3,\n",
        "        random_state=42,\n",
        "        verbose=1\n",
        "    )\n",
        "    search.fit(X_train, y_train)\n",
        "    best_params = search.best_estimator_.named_steps['model'].get_params()\n",
        "    print('Best params:', search.best_params_)\n",
        "\n",
        "model = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', XGBClassifier(**best_params))\n",
        "])\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "probs = model.predict_proba(X_test)[:, 1]\n",
        "preds = model.predict(X_test)\n",
        "\n",
        "metrics = {\n",
        "    'accuracy': model.score(X_test, y_test),\n",
        "    'roc_auc': roc_auc_score(y_test, probs),\n",
        "    'pr_auc': average_precision_score(y_test, probs)\n",
        "}\n",
        "precision_vals, recall_vals, _ = precision_recall_curve(y_test, probs)\n",
        "f1_scores = 2 * (precision_vals * recall_vals) / (precision_vals + recall_vals + 1e-9)\n",
        "metrics['f1'] = float(np.max(f1_scores))\n",
        "print('XGBoost metrics:', metrics)\n",
        "print('\n",
        "Classification report:\n",
        "', classification_report(y_test, preds, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plots and model persistence\n",
        "\n",
        "Save confusion matrix, ROC, and precision-recall curves for the XGBoost model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cm = confusion_matrix(y_test, preds, labels=[0, 1])\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=['Non-hit', 'Hit'])\n",
        "disp.plot(values_format='d')\n",
        "plt.title('XGBoost Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / 'xgboost_confusion_matrix.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, probs)\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "ax.plot(fpr, tpr, label=f\"ROC AUC = {metrics['roc_auc']:.3f}\")\n",
        "ax.plot([0, 1], [0, 1], '--', color='gray')\n",
        "ax.set_title('XGBoost ROC Curve')\n",
        "ax.set_xlabel('False Positive Rate')\n",
        "ax.set_ylabel('True Positive Rate')\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "fig.savefig(FIG_DIR / 'xgboost_roc.png', dpi=300)\n",
        "plt.close(fig)\n",
        "\n",
        "precision_vals, recall_vals, _ = precision_recall_curve(y_test, probs)\n",
        "fig, ax = plt.subplots(figsize=(5, 4))\n",
        "ax.plot(recall_vals, precision_vals, label=f\"PR AUC = {metrics['pr_auc']:.3f}\")\n",
        "ax.set_title('XGBoost Precision-Recall Curve')\n",
        "ax.set_xlabel('Recall')\n",
        "ax.set_ylabel('Precision')\n",
        "ax.legend()\n",
        "fig.tight_layout()\n",
        "fig.savefig(FIG_DIR / 'xgboost_pr.png', dpi=300)\n",
        "plt.close(fig)\n",
        "\n",
        "model_path = MODEL_DIR / 'final_xgboost.pkl'\n",
        "joblib.dump(model, model_path)\n",
        "print(f'Saved XGBoost model to {model_path}')\n",
        "\n",
        "with open(MODEL_DIR / 'xgboost_metrics.json', 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print('Stored XGBoost metrics for comparison.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SHAP interpretability\n",
        "\n",
        "Compute SHAP values on a sample for efficiency, then visualize feature impact with bar and beeswarm plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "explainer = shap.TreeExplainer(model.named_steps['model'])\n",
        "sample_size = min(1000, len(X_train))\n",
        "shap_sample = X_train.sample(sample_size, random_state=42)\n",
        "shap_values = explainer.shap_values(shap_sample)\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "shap.summary_plot(shap_values, shap_sample, plot_type='bar', show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / 'shap_feature_importance.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "shap.summary_plot(shap_values, shap_sample, show=False)\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_DIR / 'shap_summary_detailed.png', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print('Saved SHAP plots to figures/.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare against baseline\n",
        "\n",
        "Load Week 2 metrics (if available) to quantify the lift from XGBoost."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "comparison = {'xgboost': metrics}\n",
        "if BASELINE_METRICS.exists():\n",
        "    with open(BASELINE_METRICS) as f:\n",
        "        comparison['log_reg'] = json.load(f)\n",
        "\n",
        "print(json.dumps(comparison, indent=2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}